{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import xlrd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import excelSave as save\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import dateutil.relativedelta\n",
    "import calendar\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我手头的项目是要爬2010年到现在每个月/每一天的关于同居的微博。目前常见的微博爬虫有三个目标网站，一个是pc端口s.weibo.com，一个是智能手机端口m.weibo.cn，一个是非常老的手机端口weibo.cn。很多微博爬虫都采用智能手机端端口，因为可以爬到很多数据，只要不停往下滑应该就能爬完。但是我目前还没有发现智能手机端口如何搜索指定的日期或时间段，这就不得不用pc端口或者非常老的那个手机端口了。\n",
    "\n",
    "非常老的手机端口的好处在于不用管‘展开全文’，pc端需要展开原文。而且每一个日期可以搜索到100页，pc端只能搜索到50页。虽然可能pc端每一页比手机端口要多，但是应该还是这个端口能爬到的更多一点。第三个原因是可以直接勾选原创微博，省去了看上去爬了很多，但实际上爬完了还需要删除所有的转发的过程（虽然复制粘贴的还是要额外删除）。\n",
    "\n",
    "用selenium是因为微博会反爬虫，selenium可以模拟正常登陆的流程，而且一定要在每一次点击一个页面之后停顿几秒钟（sleep），不然很容易被封号甚至封IP。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#这是每个月的开始结束日期，我先试试每个月的，这样样本数量小一点\n",
    "#This is monthly start/enddate, it has much smaller sample.I'll do it for now\n",
    "\n",
    "YEAR = 2010\n",
    "MONTH = 1\n",
    "DAY = 1\n",
    "\n",
    "date = datetime(YEAR,MONTH,DAY)\n",
    "startdate = []\n",
    "for i in range(12):\n",
    "    year = date.strftime(\"%Y\")\n",
    "    month = date.strftime(\"%m\")\n",
    "    day = date.strftime(\"%d\")\n",
    "    #变成string turn date into string\n",
    "    startstring = year+month+day\n",
    "    startdate.append(startstring)\n",
    "    \n",
    "    #下一个月 Move forward by month\n",
    "    date = datetime(date.year,date.month,date.day) + dateutil.relativedelta.relativedelta(months=1)\n",
    "\n",
    "date = datetime(YEAR,MONTH,DAY)\n",
    "enddate = []\n",
    "for i in range(12):\n",
    "    year = date.strftime(\"%Y\")\n",
    "    month = date.strftime(\"%m\")\n",
    "    #用calender取月末  Last day in month using calender\n",
    "    day = str(calendar.monthrange(date.year,date.month)[1])\n",
    "    #变成string turn date into string\n",
    "    startstring = year+month+day\n",
    "    enddate.append(startstring)\n",
    "    \n",
    "    #下一个月 Move forward by month\n",
    "    date = datetime(date.year,date.month,date.day) + dateutil.relativedelta.relativedelta(months=1)\n",
    "    \n",
    "date = datetime(YEAR,MONTH,DAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20100131',\n",
       " '20100228',\n",
       " '20100331',\n",
       " '20100430',\n",
       " '20100531',\n",
       " '20100630',\n",
       " '20100731',\n",
       " '20100831',\n",
       " '20100930',\n",
       " '20101031',\n",
       " '20101130',\n",
       " '20101231']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enddate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#我打算最终的项目一年一年的下载数据 I plan on scraping yealy data for my final project but not yet\n",
    "#这是一年里的每天 This is everyday in a year\n",
    "#每天的日期储存在days里 For reiteration through each day\n",
    "#还没写完 unfinished\n",
    "\n",
    "date = datetime(2010,1,1)\n",
    "days = []\n",
    "\n",
    "for i in range(35): \n",
    "    year = date.strftime(\"%Y\")\n",
    "    month = date.strftime(\"%m\")\n",
    "    day = date.strftime(\"%d\")\n",
    "    datestring = year+month+day\n",
    "    days.append(datestring)\n",
    "    \n",
    "    #加一天 add one day\n",
    "    date += timedelta(days=1)\n",
    "    \n",
    "date = datetime(2010,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始自动登陆，若出现验证码手动验证.Loading\n",
      "暂停5秒，用于验证码验证\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    username = \"17064888409\" #用户名username\n",
    "    password = \"rw297421\" #密码password\n",
    "    driver = webdriver.Chrome()#可以换成firefox.Can use firefox\n",
    "    \n",
    "    \n",
    "#登陆 Login\n",
    "driver.get('https://weibo.cn/pub/?vt=' )\n",
    "   \n",
    "elem = driver.find_element_by_xpath(\"//*[@class='ut']/a[1]\").click();\n",
    "time.sleep(1)\n",
    "    \n",
    "print(\"开始自动登陆，若出现验证码手动验证.Loading\")\n",
    "time.sleep(1)\n",
    "\n",
    "elem = driver.find_element_by_xpath(\"//*[@id='loginName']\");\n",
    "elem.send_keys(username)\n",
    "elem = driver.find_element_by_xpath(\"//*[@id='loginPassword']\");\n",
    "elem.send_keys(password)\n",
    "elem = driver.find_element_by_xpath(\"//*[@id='loginAction']\");\n",
    "elem.send_keys(Keys.ENTER)  \n",
    "print(\"暂停5秒，用于验证码验证\")\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "#点开搜索页面 Open search tap\n",
    "driver.find_element_by_xpath(\"//a[contains(text(),'搜索')]\").click()\n",
    "driver.find_element_by_xpath(\"//a[contains(text(),'高级搜索')]\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "#输入关键词 Input Keywords\n",
    "#我这里是\"同居\" In this case 'cohabitation'\n",
    "elem = driver.find_element_by_xpath(\"//*[@type='text']\")\n",
    "elem.send_keys('同居')\n",
    "\n",
    "#勾选原创 Click original posts\n",
    "driver.find_element_by_xpath(\"//*[@name='hasori']\").click()\n",
    "\n",
    "#开始年月日 Start data e.g, 20200101\n",
    "elem = driver.find_element_by_xpath(\"//*[@name='starttime']\")\n",
    "elem.send_keys(startdate)\n",
    "\n",
    "#结束年月日 End data e.g, 20200131\n",
    "elem = driver.find_element_by_xpath(\"//*[@name='endtime']\")\n",
    "elem.clear()\n",
    "elem.send_keys(enddate)\n",
    "time.sleep(1)\n",
    "\n",
    "#搜索 Search\n",
    "driver.find_element_by_xpath(\"//*[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#开始爬微博scraping,注意elements是可以抓取多个，element只能抓一个\n",
    "#start scraping. Notice elements not element. Elements can find multiple element\n",
    "\n",
    "usernames = []\n",
    "user_links = []\n",
    "posts = []\n",
    "likes = []\n",
    "reblogs = []\n",
    "comments = []\n",
    "comment_links = []\n",
    "post_date = []\n",
    "post_time = []\n",
    "\n",
    "def scrape_one_page(driver):\n",
    "    #找到发微博的用户名和连接\n",
    "    #Get username and href link\n",
    "    elem = driver.find_elements_by_xpath(\"//*[@class='nk']\")\n",
    "    for post in elem:\n",
    "        usernames.append(post.text)\n",
    "        user_links.append(post.get_attribute('href'))\n",
    "\n",
    "    #找到微博内容\n",
    "    #Get post content\n",
    "    elem = driver.find_elements_by_xpath(\"//*[@class='ctt']\")\n",
    "    for post in elem:\n",
    "        posts.append(post.text)\n",
    "\n",
    "    #点赞\n",
    "    #likes\n",
    "    likes_temp = []\n",
    "    elem = driver.find_elements_by_xpath(\"//a[contains(text(),'赞')]\")\n",
    "    for like in elem:\n",
    "        likes_temp.append(like.text)\n",
    "    for like in likes_temp:\n",
    "        like = re.sub(r'\\D', '', like) #去除掉‘赞’这个字只保留数字Delete 'likes' text\n",
    "        likes.append(like)\n",
    "    \n",
    "    #转发评论\n",
    "    #reblogs\n",
    "    reblog_temp = []\n",
    "    elem = driver.find_elements_by_xpath(\"//a[contains(text(),'转发')]\")\n",
    "    for reblog in elem:\n",
    "        reblog_temp.append(reblog.text)\n",
    "    for reblog in reblog_temp:\n",
    "        reblog = re.sub(r'\\D', '', reblog) #保留数字keep the number\n",
    "        reblogs.append(reblog)  \n",
    "\n",
    "    #评论和评论的链接comment and links to comment section\n",
    "    comment_temp = []\n",
    "    elem = driver.find_elements_by_xpath(\"//a[contains(text(),'评论')]\")\n",
    "    for comment in elem:\n",
    "        comment_temp.append(comment.text)\n",
    "        comment_links.append(comment.get_attribute('href'))#评论的链接links to comment\n",
    "    for comment in comment_temp:\n",
    "        comment = re.sub(r'\\D', '', comment) #保留数字keep the number\n",
    "        comments.append(comment)  \n",
    "\n",
    "    #发布日期和时间\n",
    "    post_date = []\n",
    "    elem = driver.find_elements_by_xpath(\"//*[@class='ct']\")\n",
    "    for time in elem:\n",
    "        post_date.append(time.text.split(' ')[0])\n",
    "        post_time.append(time.text.split(' ')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scrape_one_page(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "#一页爬完了爬下一页Next page\n",
    "#driver.find_element_by_xpath(\"//a[contains(text(),'下页')]\").click()\n",
    "NextPage = driver.find_element_by_xpath(\"//*[@class='pa']/form/div/a[1]\")\n",
    "NextPage.click()\n",
    "time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_elements_by_xpath(\"//*[@class='pa']\")\n",
    "for page in elem:\n",
    "    page = page.text.split(' ')[4:]\n",
    "    for p in page:\n",
    "        page_number = p[:-1]\n",
    "        page_number = page_number.split('/')\n",
    "        current_page = int(page_number[0])\n",
    "        max_page = int(page_number[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@name='hasori']\"}\n  (Session info: chrome=80.0.3987.122)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-355-63b122a29656>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#勾选原创 Click original posts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//*[@name='hasori']\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m#开始年月日 Start data e.g, 20200101\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div/td[1]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \"\"\"\n\u001b[1;32m--> 394\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//*[@name='hasori']\"}\n  (Session info: chrome=80.0.3987.122)\n"
     ]
    }
   ],
   "source": [
    "if current_page == max_page:\n",
    "   #点开‘更多’ Open'more'\n",
    "    driver.find_element_by_xpath(\"//a[contains(text(),'更多')]\").click()\n",
    "    \n",
    "    #开始年月日 Start data e.g, 20200101\n",
    "    elem = driver.find_element_by_xpath(\"//*[@name='starttime']\")\n",
    "    elem.send_keys(startdate)\n",
    "\n",
    "    #结束年月日 End data e.g, 20200131\n",
    "    elem = driver.find_element_by_xpath(\"//*[@name='endtime']\")\n",
    "    elem.clear()\n",
    "    elem.send_keys(enddate)\n",
    "    time.sleep(1)\n",
    "\n",
    "    #搜索 Search\n",
    "    driver.find_element_by_xpath(\"//*[@type='submit']\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = '4/65页'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4'"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= x.split('/')\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-333-54fa0d700eec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "x[:-1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 65/65-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if a == 0:\n",
    "    b = 1\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['下页 上页 首页  4/65页']"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elem = driver.find_elements_by_xpath(\"//*[@class='pa']\")\n",
    "page_number = []\n",
    "for post in elem:\n",
    "    page_number.append(post.text)\n",
    "page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-271-051ff8bd5c99>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mpage_number\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpage_number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for a in page_number:\n",
    "    a = a.split(' ')\n",
    "    page_number.append(a)\n",
    "page_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\d+\\/\\d+页')\n",
    "\n",
    "elements = driver.find_elements_by_css_selector(\"type.submit\")\n",
    "for element in elements:\n",
    "    match = pattern.match(element.text)\n",
    "    if match:\n",
    "        print(element.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n",
      "['0', '0', '0', '0', '4', '0', '0', '0', '0', '0']\n",
      "['1', '0', '0', '5', '10', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "print(likes)\n",
    "print(reblogs)\n",
    "print(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31',\n",
       " '2010-01-31']"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_date = []\n",
    "elem = driver.find_elements_by_xpath(\"//*[@class='ct']\")\n",
    "for time in elem:\n",
    "    post_date.append(time.text.split(' ')[0])\n",
    "post_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = []\n",
    "userlink = []\n",
    "username = driver.find_elements_by_xpath(\"//*[@class='nk']\")\n",
    "for a in username:\n",
    "    usernames.append(a.text)\n",
    "    userlink.append(a.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0'], ['0'], ['0'], ['0'], ['0'], ['0'], ['0'], ['0']]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes = []\n",
    "elem = driver.find_elements_by_xpath(\"//*[@class='c']/div[1]/a[2]\")\n",
    "for like in elem:\n",
    "    like = re.findall(r'\\d+', like.text) \n",
    "    likes.append(like)\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '0', '0', '0', '0', '0', '0', '0']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes = []\n",
    "likes_temp = []\n",
    "elem = driver.find_elements_by_xpath(\"//*[@class='c']/div[1]/a[2]\")\n",
    "for like in elem:\n",
    "    likes_temp.append(like.text)\n",
    "for like in likes_temp:\n",
    "    like = re.sub(r'\\D', '', like)\n",
    "    likes.append(like)\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '评论[1]'\n",
    "a = re.sub(r'\\D', '',a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-71badc95d82d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlike\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlikes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mlike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'(?!\\d)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m''\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mlike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlikes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "for like in likes:\n",
    "    like.replace(r'(?!\\d)','' , like)\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes = []\n",
    "elem = driver.find_elements_by_xpath(\"//*[@class='c']/div[1]/a[2]\")\n",
    "for like in elem:\n",
    "    like = re.findall(r'\\d+', like.text) \n",
    "    likes.append(like)\n",
    "likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':婚礼不是同居的广告。鲁迅', ':昨日，一河南商丘22岁男子身体突然起火并严重烧伤其同居女友，目前2人在医院观察，男子口不能言。在世界上，人体自燃现象十分罕见，但也事实存在，有很多人都是自身突然起火然后烧个精光，侥幸存活的很少。在大陆这是首次。', ':2010年1月16日，位于郑州的中原工学院内的一间教室内，一场名为《你我健康青春同伴教育》的青年志愿者活动正在进行。志愿者通过“大学生同居能不能被理解？”的讨论，与大学生讨论正确的恋爱观问题。', ':张敬轩其实一直很喜欢，从第一次登台唱(过云雨)，到后来迷上他的打扮。再到后来知道他和关智斌同居。原来我的雷达没有错，果然是同路人', ':原来列侬也有小三，她的名字叫May Pang,自1973年夏至1975年初，与Lennon相爱并同居在一起。Pang是美国第二代移民，父母来自江浙，并为她起了一个中国名字：庞凤仪。', ':@xuechengfashi 优婆夷说：凡是来这里见我色相的，听我音声的，记念我的，或者与我同居共住的，给我服事的，都不会空过。他们一切的病苦除灭了，烦恼远离了，进入无碍的清净。我增长他们的善根，引他们走入功德之门。', ':#房子#家也不算小，却要与肉同居，到处都是东西，箱子，柜子，人给物让位，颠倒颠倒，还越来越多，外来物种入侵。', ':六大成绩:房产改革口袋掏空 教育改革父母逼疯 医疗改革提前送终 企业改革下岗停工 政府改革机构臃肿 婚姻改革同居成风', ':我的女朋友也叫丫头。。。 好书推荐：《白领手记：和空姐同居的日子》 http://sinaurl.cn/hIkyO', ':GLEE+LU+NYILU+Bro+TVD+好想+家教+毀滅六人+近所+人龍+新同居 以上先']\n"
     ]
    }
   ],
   "source": [
    "print(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-6-c6754c682654>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-c6754c682654>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    if os.path.exists(book_name_xls):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "#创建文件\n",
    "    if os.path.exists(book_name_xls):\n",
    "        print(\"文件已存在\")\n",
    "    else:\n",
    "        print(\"文件不存在，重新创建\")\n",
    "        value_title = [[\"rid\", \"用户名称Username\", \"微博等级\", \n",
    "                        \"微博内容\", \"微博转发量\",\"微博评论量\",\n",
    "                        \"微博点赞\",\"发布时间\",\"搜索关键词\",\n",
    "                        \"话题名称\",\"话题讨论数\",\"话题阅读数\"],]\n",
    "        save.write_excel_xls(book_name_xls, sheet_name_xls, \n",
    "                             value_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "    yuedu_taolun = driver.find_element_by_xpath(\"//*[@id='app']/div[1]/div[1]/div[2]/div/div/div[2]/h4[2]\").text\n",
    "    yuedu = yuedu_taolun.split(\" \")[0]\n",
    "    taolun = yuedu_taolun.split(\" \")[1]\n",
    "    time.sleep(2)\n",
    "    name = keyword\n",
    "    shishi_element = driver.find_element_by_xpath(\"//*[@class='scroll-box nav_item']/ul/li/span[text()='实时']\")\n",
    "    driver.execute_script('arguments[0].click()',shishi_element) \n",
    "    get_current_weibo_data(elems,book_name_xls,name,yuedu,taolun,maxWeibo) #爬取实时\n",
    "    time.sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def spider(username,password,driver,book_name_xls,sheet_name_xls,keyword,maxWeibo):\n",
    "    \n",
    "    #创建文件\n",
    "    if os.path.exists(book_name_xls):\n",
    "        print(\"文件已存在\")\n",
    "    else:\n",
    "        print(\"文件不存在，重新创建\")\n",
    "        value_title = [[\"rid\", \"用户名称\", \"微博等级\", \"微博内容\", \"微博转发量\",\"微博评论量\",\"微博点赞\",\"发布时间\",\"搜索关键词\",\"话题名称\",\"话题讨论数\",\"话题阅读数\"],]\n",
    "        save.write_excel_xls(book_name_xls, sheet_name_xls, value_title)\n",
    "    \n",
    "    #加载驱动，使用浏览器打开指定网址  \n",
    "    driver.set_window_size(452, 790)\n",
    "    driver.get('https://weibo.cn/pub/?vt=' )\n",
    "   \n",
    "    elem = driver.find_element_by_xpath(\"//*[@class='ut']/div[1]\").click();\n",
    "    time.sleep(1)\n",
    "    \n",
    "    print(\"开始自动登陆，若出现验证码手动验证\")\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "    #登陆\n",
    "    elem = driver.find_element_by_xpath(\"//*[@id='loginName']\");\n",
    "    elem.send_keys(username)\n",
    "    elem = driver.find_element_by_xpath(\"//*[@id='loginPassword']\");\n",
    "    elem.send_keys(password)\n",
    "    elem = driver.find_element_by_xpath(\"//*[@id='loginAction']\");\n",
    "    elem.send_keys(Keys.ENTER)  \n",
    "    print(\"暂停20秒，用于验证码验证\")\n",
    "    time.sleep(20)\n",
    "\n",
    "    \n",
    "    #判断页面是否加载出\n",
    "    while 1:  # 循环条件为1必定成立\n",
    "        result = isPresent()\n",
    "        print ('判断页面1成功 0失败  结果是=%d' % result )\n",
    "        if result == 1:\n",
    "            elems = driver.find_elements_by_css_selector('div.line-around.layout-box.mod-pagination > a:nth-child(2) > div > select > option')\n",
    "            #return elems #如果封装函数，返回页面\n",
    "            break\n",
    "        else:\n",
    "            print ('页面还没加载出来呢')\n",
    "            time.sleep(20)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #搜索关键词\n",
    "    elem = driver.find_element_by_xpath(\"//*[@class='m-text-cut']\").click();\n",
    "    time.sleep(2)\n",
    "    elem = driver.find_element_by_xpath(\"//*[@type='search']\");\n",
    "    elem.send_keys(keyword)\n",
    "    elem.send_keys(Keys.ENTER)\n",
    "\n",
    "    time.sleep(5)\n",
    "    #elem = driver.find_element_by_xpath(\"//*[@id='app']/div[1]/div[1]/div[3]/div/div/div/div[1]/span[2]/span[1]\")\n",
    "\n",
    "    #elem.click()\n",
    "    print(\"超话链接获取完毕，休眠2秒\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    yuedu_taolun = driver.find_element_by_xpath(\"//*[@id='app']/div[1]/div[1]/div[2]/div/div/div[2]/h4[2]\").text\n",
    "    yuedu = yuedu_taolun.split(\" \")[0]\n",
    "    taolun = yuedu_taolun.split(\" \")[1]\n",
    "    time.sleep(2)\n",
    "    name = keyword\n",
    "    shishi_element = driver.find_element_by_xpath(\"//*[@class='scroll-box nav_item']/ul/li/span[text()='实时']\")\n",
    "    driver.execute_script('arguments[0].click()',shishi_element) \n",
    "    get_current_weibo_data(elems,book_name_xls,name,yuedu,taolun,maxWeibo) #爬取实时\n",
    "    time.sleep(2)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    username = \"17064888409\" #你的微博登录名\n",
    "    password = \"rw297421\" #你的密码\n",
    "    driver = webdriver.Chrome()#你的chromedriver的地址\n",
    "    book_name_xls = \"#人大法工委回应未婚同居合法化#.xls\" #填写你想存放excel的路径，没有文件会自动创建\n",
    "    sheet_name_xls = '微博数据' #sheet表名\n",
    "    maxWeibo = 5000 #设置最多多少条微博\n",
    "    keywords = [\"#人大法工委回应未婚同居合法化#\"] \n",
    "    for keyword in keywords:\n",
    "        spider(username,password,driver,book_name_xls,sheet_name_xls,keyword,maxWeibo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elem = driver.find_element_by_xpath(\"//*[@class='ut']/a[1]\").click();\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#点开搜索页面 Open search tap\n",
    "driver.find_element_by_xpath(\"//*[@class='n']/a[4]\").click()\n",
    "time.sleep(1)\n",
    "\n",
    "#输入关键词 Input Keywords\n",
    "#我这里是\"同居\" In this case 'cohabitation'\n",
    "elem = driver.find_element_by_xpath(\"//*[@type='text']\")\n",
    "elem.send_keys('同居')\n",
    "elem.send_keys(Keys.ENTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
